{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5PejohTK9wC"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests\n",
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmV7YTNsLWuf"
      },
      "source": [
        "response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "DK1iAfCoPNiL",
        "outputId": "a1d21905-2428-40ca-ef42-5de91dfdf995"
      },
      "source": [
        "response.text[:1500]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and\\nis presented in cooperation with World Library, Inc., from their\\nLibrary of the Future and Shakespeare CDROMS.  Project Gutenberg\\noften releases Etexts that are NOT placed in the Public Domain!!\\n\\nShakespeare\\n\\n*This Etext has certain copyright implications you should read!*\\n\\n<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\\nPERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\\nCOMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\\nSERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\\n\\n*Project Gutenberg is proud to cooperate with The World Library*\\nin the presentation of The Complete Works of William Shakespeare\\nfor your reading for education and entertainment.  HOWEVER, THIS\\nIS NEITHER SHAREWARE NOR PUBLIC DOMAIN. . .AND UNDER THE LIBRARY\\nOF THE FUTURE CONDITIONS OF THIS PRESENTATION. . .NO CHARGES MAY\\nBE MADE FOR *ANY* ACCESS TO THIS MATERIAL.  YOU ARE ENCOURAGED!!\\nTO GIVE IT AWAY TO ANYONE YOU LIKE, BUT NO CHARGES ARE ALLOWED!!\\n\\n\\n**Welcome To The World of Free Plain Vanilla Electronic Texts**\\n\\n**Etexts Readable By Both Humans and By Computers, Since 1971**\\n\\n*These Etexts Prepared By Hundreds of Volunteers and Donations*\\n\\nInforma'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EYgC4IYdPqCZ",
        "outputId": "16bb87f2-6664-4088-eb0f-4b6068ff6e65"
      },
      "source": [
        "data = response.text.split('\\n')\n",
        "data[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yIOxbNB1Pt9R",
        "outputId": "465c50c6-3566-44f7-ec49-5ebdbde6310e"
      },
      "source": [
        "data = data[253:]\n",
        "data[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  From fairest creatures we desire increase,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CBwiy3RPzXi",
        "outputId": "b63564e2-d4e4-4f4f-cc70-9a52cd5f1a11"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "vCPykDXrQewy",
        "outputId": "7406a7a1-aeba-4387-f5ea-8991c40e567e"
      },
      "source": [
        "data = \" \".join(data)\n",
        "data[:1000]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  From fairest creatures we desire increase,   That thereby beauty's rose might never die,   But as the riper should by time decease,   His tender heir might bear his memory:   But thou contracted to thine own bright eyes,   Feed'st thy light's flame with self-substantial fuel,   Making a famine where abundance lies,   Thy self thy foe, to thy sweet self too cruel:   Thou that art now the world's fresh ornament,   And only herald to the gaudy spring,   Within thine own bud buriest thy content,   And tender churl mak'st waste in niggarding:     Pity the world, or else this glutton be,     To eat the world's due, by the grave and thee.                        2   When forty winters shall besiege thy brow,   And dig deep trenches in thy beauty's field,   Thy youth's proud livery so gazed on now,   Will be a tattered weed of small worth held:     Then being asked, where all thy beauty lies,   Where all the treasure of thy lusty days;   To say within thine own deep sunken eyes,   Were an all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAN1y7KDQk-x",
        "outputId": "0c2dc25a-cd83-428f-ff0f-004829238dd9"
      },
      "source": [
        "def clean_text(doc):\n",
        "  tokens = doc.split()\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'might', 'bear', 'his', 'memory', 'but', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'thy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqxMiPwiRUSh",
        "outputId": "76932891-5d68-47df-fc7b-a68c3aca7c30"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "898199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Vxd5u6Tc0h",
        "outputId": "5ef54fe1-c112-47da-e67e-38a33fe59978"
      },
      "source": [
        "length = 30 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "    break\n",
        "\n",
        "print(len(lines))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbBBMexsWztx"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyx_V7t6ZkSz"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch2TekItc7KT",
        "outputId": "27faabc7-cd74-4b33-e472-ae21066d3b21"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  47, 1408, 1264,   37,  451, 1406,    9, 2766, 1158, 1213,  171,\n",
              "        132,  269,   20,   24,    1, 4782,   87,   30,   98, 4781,   18,\n",
              "        715, 1263,  171,  211,   18,  829,   20,   27])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgEDMARqc-c4"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_PIjZnmdKI4"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC2jCO48eEys",
        "outputId": "0a52c12d-0c9b-43c0-eb68-ed1ca3e29869"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA2nilz_dVO5",
        "outputId": "acd25e26-0c65-4954-fc81-ddd1907b6014"
      },
      "source": [
        "y[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VygPzgYhlz1Q",
        "outputId": "7e43e6e4-341a-4686-e875-9fb456ff3b49"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKZesm4VeNe4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 30, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW00cRfOlyfY",
        "outputId": "dde93b2d-0a2a-445f-8e6d-8228deae34f2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 30, 30)            390270    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 30, 100)           52400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13009)             1313909   \n",
            "=================================================================\n",
            "Total params: 1,847,079\n",
            "Trainable params: 1,847,079\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H8Y5eXdnWSQ"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sNlLKwBnaSP",
        "outputId": "ed857f00-314d-4cd7-bd12-ba8691ce50f0"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 50)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 6.8859 - accuracy: 0.0301\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 232s 296ms/step - loss: 6.5364 - accuracy: 0.0417\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 6.3472 - accuracy: 0.0547\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 6.1761 - accuracy: 0.0696\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 6.0446 - accuracy: 0.0786\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 5.9391 - accuracy: 0.0846\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 226s 290ms/step - loss: 5.8438 - accuracy: 0.0896\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 5.7552 - accuracy: 0.0951\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 5.6691 - accuracy: 0.0995\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 245s 313ms/step - loss: 5.5896 - accuracy: 0.1027\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 255s 326ms/step - loss: 5.5143 - accuracy: 0.1055\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 245s 314ms/step - loss: 5.4427 - accuracy: 0.1082\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 5.3722 - accuracy: 0.1106\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 224s 287ms/step - loss: 5.3042 - accuracy: 0.1137\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 5.2374 - accuracy: 0.1155\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 5.1716 - accuracy: 0.1174\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 5.1078 - accuracy: 0.1201\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 5.0469 - accuracy: 0.1230\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.9894 - accuracy: 0.1253\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 232s 296ms/step - loss: 4.9355 - accuracy: 0.1286\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 236s 301ms/step - loss: 4.8862 - accuracy: 0.1318\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.8395 - accuracy: 0.1352\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 234s 299ms/step - loss: 4.7964 - accuracy: 0.1381\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.7563 - accuracy: 0.1417\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 233s 298ms/step - loss: 4.7196 - accuracy: 0.1447\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.6831 - accuracy: 0.1480\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 222s 284ms/step - loss: 4.6499 - accuracy: 0.1515\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 4.6186 - accuracy: 0.1537\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 222s 285ms/step - loss: 4.5880 - accuracy: 0.1565\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 222s 284ms/step - loss: 4.5583 - accuracy: 0.1597\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 221s 283ms/step - loss: 4.5310 - accuracy: 0.1621\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5021 - accuracy: 0.1651\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.4761 - accuracy: 0.1681\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.4505 - accuracy: 0.1702\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.4247 - accuracy: 0.1729\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.3999 - accuracy: 0.1754\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 234s 300ms/step - loss: 4.3758 - accuracy: 0.1773\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 4.3519 - accuracy: 0.1804\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.3297 - accuracy: 0.1831\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 247s 316ms/step - loss: 4.3046 - accuracy: 0.1857\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 256s 328ms/step - loss: 4.2834 - accuracy: 0.1873\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 251s 320ms/step - loss: 4.2615 - accuracy: 0.1906\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 258s 330ms/step - loss: 4.2416 - accuracy: 0.1929\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.2201 - accuracy: 0.1957\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.1995 - accuracy: 0.1978\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.1805 - accuracy: 0.2000\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 237s 304ms/step - loss: 4.1601 - accuracy: 0.2028\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.1405 - accuracy: 0.2056\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.1211 - accuracy: 0.2078\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.1024 - accuracy: 0.2094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fed795c2080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zPV4YDU1nnCP",
        "outputId": "ff0f398a-ede0-4b9f-afc9-e3ce3adef90a"
      },
      "source": [
        "seed_text=lines[1]\n",
        "seed_text"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fairest creatures we desire increase that thereby beautys rose might never die but as the riper should by time decease his tender heir might bear his memory but thou contracted to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RA6Kku9R__r"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    \n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "WhRPJxcPSvEE",
        "outputId": "668da14a-2af6-4e78-d410-47479efe1f9a"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wilful barks to qualify in ranks and wrinkles of the world and giddy censure and mischief thereto view and with a choir of weakness to th smothering of the castle enter king and ladies sovereign of the fusty is the remainder of the war and in the capitol of the castle enter marcius with drum and colours with artless absence and heat toward the pangs of twins appeard all the king and to the capitol exceed the antiates to be requires out of the world and to the sessions of the groundlings and seconded and we discovered unhand me world'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se8Omzq9SyVI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}